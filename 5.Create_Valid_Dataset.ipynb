{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocess Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-C7OTd7nwnz",
        "outputId": "407c1656-7f57-450c-b608-a2d6b275a891"
      },
      "outputs": [],
      "source": [
        "use_google_drive = False\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  from google.colab import drive\n",
        "  !pip install webdataset\n",
        "  use_google_drive = True\n",
        "except Exception:\n",
        "  pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqNaCZACzVjt"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import webdataset as wds\n",
        "from torchvision import transforms\n",
        "import os\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Definitions and Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_image_count = 0 #set 0 for all\n",
        "write_fulldataset = True\n",
        "write_splitdatasets = True\n",
        "\n",
        "model_name = \"alexnet\" #resnet18, vgg11_bn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bpgy4bTnktG"
      },
      "outputs": [],
      "source": [
        "if use_google_drive:\n",
        "  model_load_file = \"/content/gdrive/MyDrive/ColabData/amazon/shoes-model-5-singlecolor-rgb.model\"\n",
        "  dataset_file = \"file:///content/gdrive/MyDrive/ColabData/amazon/shoes-224-full-3.tar\"\n",
        "  dataset_folder = \"/content/gdrive/MyDrive/ColabData/amazon/\"\n",
        "\n",
        "  drive.mount(\"/content/gdrive\")\n",
        "else:\n",
        "  model_load_file = \"model/shoes-model-5-singlecolor-rgb.model\"\n",
        "  dataset_file = f\"file://{os.getcwd()}/dataset/shoes-224-full-3.tar\".replace('\\\\', '/')\n",
        "  dataset_folder = \"dataset\\\\\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classes = [\"black\", \"white\", \"gray\", \"red\", \"green\", \"blue\", \"orange\", \"purple\", \"yellow\", \"pink\", \"brown\", \"multicolor\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFiEGDU5zVj0"
      },
      "source": [
        "## Load Model and Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5_wct4xzVj1",
        "outputId": "2a17e529-ce4b-4e15-d3be-38feba625c4a"
      },
      "outputs": [],
      "source": [
        "model = torch.hub.load('pytorch/vision:v0.10.0', model_name, pretrained=False, num_classes=2)\n",
        "model.load_state_dict(torch.load(model_load_file))\n",
        "model.eval()\n",
        "convnet = model.to(device)\n",
        "test_input = torch.randn(1, 3, 224, 224, device=device)\n",
        "\n",
        "test_output = convnet(test_input)\n",
        "print(test_output.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhAWYbzZkdHt"
      },
      "outputs": [],
      "source": [
        "def match_metadata(sample):\n",
        "  image_tensor = transforms.ToTensor()(sample['jpg']).unsqueeze_(0).reshape(1, 3, 224, 224).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    image_output = convnet(image_tensor)\n",
        "    image_validation = image_output.argmax(dim=1).cpu().numpy()[0]\n",
        "    validation_perc = image_output.softmax(dim=1).max().cpu().numpy()\n",
        "    sample[\"validation\"] = bin(image_validation)\n",
        "    sample[\"validation_perc\"] = bin(round(validation_perc * 100))\n",
        "  return sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKZSXOPH7li3"
      },
      "outputs": [],
      "source": [
        "dataset = (wds.WebDataset(dataset_file)\n",
        "           .decode(\"pil\", only=\"jpg\")\n",
        "           .map(match_metadata)\n",
        "           .shuffle(100)\n",
        "           )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "gocJlqKYvjmR",
        "outputId": "17650fc9-1f05-4cbc-d783-5ea7c2678011"
      },
      "outputs": [],
      "source": [
        "for item in dataset:\n",
        "  break\n",
        "\n",
        "print(f\"\"\"{item['__key__']}\n",
        "class: {classes[int(item['cls'])]}\n",
        "validation: {'valid' if int(item['validation'],2)==1 else 'invalid'} {int(item['validation_perc'],2)}%\n",
        "image sort: {int(item['sort'],2)}\"\"\")\n",
        "\n",
        "plt.imshow(item['jpg'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare Dataset(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcChLuMdTc-u"
      },
      "outputs": [],
      "source": [
        "def write2TARs(dataset, folder):\n",
        "  i = 0\n",
        "\n",
        "  dataset_id = 6\n",
        "  filefull = os.path.join(folder, f\"shoes-224-full-{dataset_id}.tar\")\n",
        "  filetraining = os.path.join(folder, f\"shoes-224-training-{dataset_id}.tar\")\n",
        "  filevalidation = os.path.join(folder, f\"shoes-224-validation-{dataset_id}.tar\")\n",
        "  filetest = os.path.join(folder, f\"shoes-224-test-{dataset_id}.tar\")\n",
        "\n",
        "  invalids, valids, training_size, validation_size, test_size = 0, 0, 0, 0, 0\n",
        "  with wds.TarWriter(filefull) as full, wds.TarWriter(filetraining) as train, wds.TarWriter(filevalidation) as validation, wds.TarWriter(filetest) as test:\n",
        "    for item in dataset:\n",
        "      result = int(item['validation'], 2)\n",
        "\n",
        "      if result == 0:\n",
        "        invalids += 1\n",
        "\n",
        "      elif result == 1:\n",
        "        if write_fulldataset:\n",
        "          full.write(item)\n",
        "          valids += 1\n",
        "\n",
        "        if write_splitdatasets:\n",
        "          if i % 10 < 6:\n",
        "            train.write(item)\n",
        "            training_size += 1\n",
        "          elif i % 10 < 8:\n",
        "            validation.write(item)\n",
        "            validation_size += 1\n",
        "          else:\n",
        "            test.write(item)\n",
        "            test_size += 1\n",
        "\n",
        "        i += 1\n",
        "        if max_image_count > 0 and i >= max_image_count:\n",
        "          break\n",
        "\n",
        "  return invalids, valids, training_size, validation_size, test_size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJN5cQKOnktK"
      },
      "outputs": [],
      "source": [
        "results = write2TARs(dataset, dataset_folder)\n",
        "\n",
        "print(f\"\"\"Validated dataset is written to files:\n",
        "# of Invalid images: {results[0]}\n",
        "\n",
        "# of Valid images: {results[1]}\n",
        "# of Training images: {results[2]}\n",
        "# of Validation images: {results[3]}\n",
        "# of Test images: {results[4]}\n",
        "\"\"\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
    },
    "kernelspec": {
      "display_name": "Python 3.10.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
