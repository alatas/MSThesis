{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-C7OTd7nwnz",
        "outputId": "407c1656-7f57-450c-b608-a2d6b275a891"
      },
      "outputs": [],
      "source": [
        "use_google_drive = False\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  from google.colab import drive\n",
        "  !pip install webdataset kornia\n",
        "  use_google_drive = True\n",
        "except Exception:\n",
        "  pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqNaCZACzVjt",
        "outputId": "b96b275f-d243-4fb5-d114-e3cd0d5532d1"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import torch\n",
        "import time\n",
        "import kornia\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import webdataset as wds\n",
        "from torchvision import transforms\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "from jinja2 import Environment\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Definitions and Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_id = 3\n",
        "no_multicolor = True #not used when dataset_id==5\n",
        "model_name = \"alexnet\" #resnet18, vgg11_bn\n",
        "learning_rate = 0.00007\n",
        "dropout = 0.1\n",
        "batch_size = 32\n",
        "color_space = 'hsl' #rgb, hsl, or hsv\n",
        "epoch_round = 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if use_google_drive:\n",
        "  model_save_file = f\"/content/gdrive/MyDrive/ColabData/amazon/shoes-model-{dataset_id}-{'singlecolor' if no_multicolor else 'multicolor'}-{color_space}.model\"\n",
        "  training_dataset_file = f\"file:///content/gdrive/MyDrive/ColabData/amazon/shoes-224-training-{dataset_id}.tar\"\n",
        "  validation_dataset_file = f\"file:///content/gdrive/MyDrive/ColabData/amazon/shoes-224-validation-{dataset_id}.tar\"\n",
        "  test_dataset_file = f\"file:///content/gdrive/MyDrive/ColabData/amazon/shoes-224-test-{dataset_id}.tar\"\n",
        "  report_folder = f\"/content/gdrive/MyDrive/ColabData/amazon/report/dataset-{dataset_id}/cnn-{'singlecolor' if no_multicolor else 'multicolor'}-{color_space}\"\n",
        "\n",
        "  drive.mount(\"/content/gdrive\")\n",
        "else:\n",
        "  model_save_file = f\"model\\\\shoes-model-{dataset_id}-{'singlecolor' if no_multicolor else 'multicolor'}-{color_space}.model\"\n",
        "  training_dataset_file = f\"file://{os.getcwd()}/dataset/shoes-224-training-{dataset_id}.tar\".replace('\\\\', '/')\n",
        "  validation_dataset_file = f\"file://{os.getcwd()}/dataset/shoes-224-validation-{dataset_id}.tar\".replace('\\\\', '/')\n",
        "  test_dataset_file = f\"file://{os.getcwd()}/dataset/shoes-224-test-{dataset_id}.tar\".replace('\\\\', '/')\n",
        "  report_folder = f\"./report/dataset-{dataset_id}/cnn-{'singlecolor' if no_multicolor else 'multicolor'}-{color_space}\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#copy to local folder to speed up\n",
        "\n",
        "if use_google_drive:\n",
        "  shutil.copyfile(training_dataset_file.replace(\"file://\", \"\"), f\"/content/shoes-224-training-{dataset_id}.tar\")\n",
        "  shutil.copyfile(validation_dataset_file.replace(\"file://\", \"\"), f\"/content/shoes-224-validation-{dataset_id}.tar\")\n",
        "  shutil.copyfile(test_dataset_file.replace(\"file://\", \"\"), f\"/content/shoes-224-test-{dataset_id}.tar\")\n",
        "\n",
        "  training_dataset_file = f\"file:///content/shoes-224-training-{dataset_id}.tar\".replace('\\\\', '/')\n",
        "  validation_dataset_file = f\"file:///content/shoes-224-validation-{dataset_id}.tar\".replace('\\\\', '/')\n",
        "  test_dataset_file = f\"file:///content/shoes-224-test-{dataset_id}.tar\".replace('\\\\', '/')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConvertColorSpace(object):\n",
        "  def __init__(self, source_colorspace='rgb', target_colorspace='hsl'):\n",
        "    self.source_colorspace = source_colorspace\n",
        "    self.target_colorspace = target_colorspace\n",
        "\n",
        "  def __call__(self, input: torch.Tensor):\n",
        "    if self.source_colorspace == self.target_colorspace:\n",
        "      return input\n",
        "    elif self.source_colorspace == 'rgb' and self.target_colorspace == 'hsl':\n",
        "      hls = kornia.color.rgb_to_hls(input)\n",
        "      return torch.cat((hls[0, :, :], hls[2, :, :], hls[1, :, :])).reshape(input.shape)\n",
        "    elif self.source_colorspace == 'rgb' and self.target_colorspace == 'hsv':\n",
        "      return kornia.color.rgb_to_hsv(input)\n",
        "    elif self.source_colorspace == 'hsl' and self.target_colorspace == 'rgb':\n",
        "      hls = torch.cat((input[0, :, :], input[2, :, :], input[1, :, :])).reshape(input.shape)\n",
        "      return kornia.color.hls_to_rgb(hls)\n",
        "    elif self.source_colorspace == 'hsv' and self.target_colorspace == 'rgb':\n",
        "      return kornia.color.hsv_to_rgb(input)\n",
        "    else:\n",
        "      raise Exception(f\"Unsupported color space {self.target_colorspace}\")\n",
        "\n",
        "  def __repr__(self):\n",
        "    return self.__class__.__name__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyD4C7of7iSD"
      },
      "outputs": [],
      "source": [
        "# Helper for visualization\n",
        "def torch_imshow(img):\n",
        "  img = ConvertColorSpace(source_colorspace=color_space, target_colorspace='rgb')(img)\n",
        "  img = np.clip(img, 0, 1)\n",
        "  img = img.permute(1, 2, 0)\n",
        "  plt.imshow(img.cpu().numpy())\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbPbqIVsNy5D",
        "outputId": "def96113-605a-41d4-f799-889f1a3a2fea"
      },
      "outputs": [],
      "source": [
        "classes = []\n",
        "\n",
        "if dataset_id != 5:\n",
        "  classes = [\"black\", \"white\", \"gray\", \"red\", \"green\", \"blue\", \"orange\", \"purple\", \"yellow\", \"pink\", \"brown\", \"multicolor\"]\n",
        "else:\n",
        "  classes = [\"invalid\", \"valid\"]\n",
        "\n",
        "def fromcls(cls):\n",
        "  return classes[cls]\n",
        "\n",
        "def tocls(cls):\n",
        "  if cls in classes:\n",
        "    return classes.index(cls)\n",
        "  else:\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "H3RruVj_eGlT",
        "outputId": "39783a46-4ff1-4c29-9d30-8b9dca4b8899"
      },
      "outputs": [],
      "source": [
        "preproc = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    ConvertColorSpace(source_colorspace='rgb', target_colorspace=color_space)\n",
        "])\n",
        "\n",
        "\n",
        "training_dataset = (wds.WebDataset(training_dataset_file)\n",
        "                    .select(predicate=lambda r: not no_multicolor or int(r[\"cls\"]) != 11)\n",
        "                    .decode(\"pil\", only=\"jpg\")\n",
        "                    .to_tuple(\"jpg\", \"cls\")\n",
        "                    .map_tuple(preproc, lambda a: int(a))\n",
        "                    .shuffle(100)\n",
        "                    )\n",
        "\n",
        "validation_dataset = (wds.WebDataset(validation_dataset_file)\n",
        "                      .select(predicate=lambda r: not no_multicolor or int(r[\"cls\"]) != 11)\n",
        "                      .decode(\"pil\", only=\"jpg\")\n",
        "                      .to_tuple(\"jpg\", \"cls\")\n",
        "                      .map_tuple(preproc, lambda a: int(a))\n",
        "                      .shuffle(100)\n",
        "                      )\n",
        "\n",
        "test_dataset = (wds.WebDataset(test_dataset_file)\n",
        "                .select(predicate=lambda r: not no_multicolor or int(r[\"cls\"]) != 11)\n",
        "                .decode(\"pil\", only=\"jpg\")\n",
        "                .to_tuple(\"jpg\", \"cls\")\n",
        "                .map_tuple(preproc, lambda a: int(a))\n",
        "                .shuffle(100)\n",
        "                )\n",
        "\n",
        "for jpg, cls in training_dataset:\n",
        "  break\n",
        "\n",
        "print(classes[cls])\n",
        "torch_imshow(jpg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7k2yPjCGzVjz"
      },
      "source": [
        "## Prepare Dataloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azVexPk6zVj0"
      },
      "outputs": [],
      "source": [
        "training_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size=batch_size)\n",
        "validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFiEGDU5zVj0"
      },
      "source": [
        "## Load Model, Loss Function and Optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5_wct4xzVj1",
        "outputId": "2a17e529-ce4b-4e15-d3be-38feba625c4a"
      },
      "outputs": [],
      "source": [
        "model = torch.hub.load('pytorch/vision:v0.10.0', model_name, pretrained=False, num_classes=len(classes), dropout=dropout)\n",
        "model.eval()\n",
        "convnet = model.to(device)\n",
        "test_input = torch.randn(batch_size, 3, 224, 224, device=device)\n",
        "test_output = convnet(test_input)\n",
        "print(test_output.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIOmsdWIzVj3"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(convnet.parameters(), lr=learning_rate)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NoeSty0zVj4"
      },
      "source": [
        "## Model Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dxY0W0OzVj4"
      },
      "outputs": [],
      "source": [
        "def check_accuracy(neuralnet, dataloader, show_matrix=False, show_report=False, save_matrix=None):\n",
        "  neuralnet.eval()\n",
        "\n",
        "  y = []\n",
        "  y_hat = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for imgs_batch, labels_batch in dataloader:\n",
        "      imgs_batch, labels_batch = imgs_batch.to(device), labels_batch.to(device)\n",
        "\n",
        "      output = neuralnet(imgs_batch)\n",
        "\n",
        "      y_hat.append(output.argmax(dim=1).cpu().numpy())\n",
        "      y.append(labels_batch.cpu().numpy())\n",
        "\n",
        "  neuralnet.train()\n",
        "\n",
        "  y = np.concatenate(y, axis=None)\n",
        "  y_hat = np.concatenate(y_hat, axis=None)\n",
        "\n",
        "  if show_matrix:\n",
        "    font = {'family': 'DejaVu Sans', 'weight': 'normal', 'size': 6}\n",
        "    plt.rc('font', **font)\n",
        "    disp = ConfusionMatrixDisplay.from_predictions(y, y_hat, labels=range(len(classes)), display_labels=classes, xticks_rotation='vertical', cmap=plt.cm.Blues, normalize=None)\n",
        "    disp.figure_.set_dpi(150)\n",
        "    if save_matrix != None:\n",
        "      disp.figure_.savefig(save_matrix, dpi=130, bbox_inches='tight')\n",
        "\n",
        "  if show_report:\n",
        "    return classification_report(y, y_hat, labels=range(len(classes)), target_names=classes, zero_division=0, output_dict=True)\n",
        "\n",
        "  accuracy = accuracy_score(y, y_hat)\n",
        "  return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def torch_imadd(index, f, img, label, color):\n",
        "  ax = f.add_subplot(6, 6, index)\n",
        "\n",
        "  img = ConvertColorSpace(source_colorspace=color_space, target_colorspace='rgb')(img)\n",
        "  img = torch.clamp(img, 0, 1)\n",
        "  img = img.permute(1, 2, 0)\n",
        "  plt.imshow(img.cpu().numpy())\n",
        "  plt.axis('off')\n",
        "  plt.title(label, loc='left', fontdict={\"color\": color})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def draw_canvas(neuralnet, dataloader, only_errors=False, save_fig=None):\n",
        "  neuralnet.eval()\n",
        "  y = []\n",
        "  y_hat = []\n",
        "\n",
        "  f = plt.figure(figsize=(4.5, 6), dpi=300)\n",
        "\n",
        "  ax = f.gca()\n",
        "  ax.axis('off')\n",
        "  ax.set(xlim=(0, 6), ylim=(6, 0.3))\n",
        "  ax.add_patch(Rectangle((0.2, 1), 5.6, 1, linewidth=0, facecolor='#efefef'))\n",
        "  ax.add_patch(Rectangle((0.2, 3), 5.6, 1, linewidth=0, facecolor='#efefef'))\n",
        "  ax.add_patch(Rectangle((0.2, 5), 5.6, 1, linewidth=0, facecolor='#efefef'))\n",
        "\n",
        "  with torch.no_grad():\n",
        "    plt.rcParams.update({'font.size': 4})\n",
        "    plt.rcParams.update({'lines.linewidth': 0.5})\n",
        "    plt.margins(0, 0)\n",
        "    plt.subplots_adjust(wspace=-0.4, hspace=0.6)\n",
        "\n",
        "    index = 1\n",
        "    for imgs_batch, labels_batch in dataloader:\n",
        "      imgs_batch, labels_batch = imgs_batch.to(device), labels_batch.to(device)\n",
        "      outputs = neuralnet(imgs_batch).softmax(dim=1).cpu().numpy()\n",
        "      truths = labels_batch.cpu().numpy()\n",
        "\n",
        "      for i, prob_dist in enumerate(outputs):\n",
        "        pred = np.argmax(prob_dist)\n",
        "        truth = truths[i]\n",
        "        perc = np.max(prob_dist, axis=0) * 100\n",
        "\n",
        "        if index <= 36 and (only_errors == False or (only_errors == True and pred != truth)):\n",
        "          color = \"green\" if pred == truth else \"red\"\n",
        "          label = f\"{classes[pred]} ({perc:.1f}%)\\n>> {classes[truth]}\"\n",
        "          torch_imadd(index, f, imgs_batch[i], label, color)\n",
        "          index += 1\n",
        "\n",
        "        y_hat.append(pred)\n",
        "        y.append(truth)\n",
        "\n",
        "  neuralnet.train()\n",
        "\n",
        "  if save_fig != None:\n",
        "    f.savefig(save_fig, dpi=300, bbox_inches='tight', pad_inches=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZJjOxS2zVj6"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(neuralnet, dataloader, optimizer, loss_fn):\n",
        "  epoch_loss = 0.0\n",
        "  i = 0\n",
        "  for imgs_batch, labels_batch in dataloader:\n",
        "    imgs_batch, labels_batch = imgs_batch.to(device), labels_batch.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = neuralnet(imgs_batch)\n",
        "    loss = loss_fn(output, labels_batch)\n",
        "    epoch_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    i += 1\n",
        "\n",
        "  return (epoch_loss / i)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWIAzelIzVj6"
      },
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YcxsjWo8LkI"
      },
      "outputs": [],
      "source": [
        "training_accuracy_list = [0.0]\n",
        "validation_accuracy_list = [0.0]\n",
        "loss_list = []\n",
        "best_accuracy = 0.0\n",
        "best_epoch = 0\n",
        "epoch = 1\n",
        "elapsed = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViSlI8cazVj6",
        "outputId": "d4014437-c76e-4bfd-a480-fd13485e4223"
      },
      "outputs": [],
      "source": [
        "if elapsed != 0:\n",
        "  print(\"previous state loaded\")\n",
        "  #return the latest state\n",
        "  convnet.load_state_dict(torch.load(model_save_file + \".last\"))\n",
        "  convnet.eval()\n",
        "\n",
        "t = time.time()\n",
        "\n",
        "for i in range(epoch_round):\n",
        "  print(f'Epoch {epoch + i}...')\n",
        "\n",
        "  epoch_loss = train_one_epoch(convnet, training_dataloader, optimizer, loss_fn)\n",
        "  loss_list.append(epoch_loss)\n",
        "  print(f'Loss: {epoch_loss:.4f}')\n",
        "\n",
        "  training_accuracy = check_accuracy(convnet, training_dataloader)\n",
        "  print(f'Training   accuracy: {training_accuracy * 100 :.2f}%')\n",
        "  validation_accuracy = check_accuracy(convnet, validation_dataloader)\n",
        "  print(f'Validation accuracy: {validation_accuracy * 100 :.2f}%')\n",
        "\n",
        "  if validation_accuracy >= best_accuracy:\n",
        "    best_accuracy = validation_accuracy\n",
        "    best_epoch = epoch + i\n",
        "    torch.save(convnet.state_dict(), model_save_file)\n",
        "    print(f\"Best accuracy so far: {best_accuracy * 100 :.2f}%\\n\")\n",
        "\n",
        "  training_accuracy_list.append(training_accuracy)\n",
        "  validation_accuracy_list.append(validation_accuracy)\n",
        "\n",
        "elapsed += time.time() - t\n",
        "\n",
        "#save the latest state and load the best model\n",
        "torch.save(convnet.state_dict(), model_save_file + \".last\")\n",
        "convnet.load_state_dict(torch.load(model_save_file))\n",
        "convnet.eval()\n",
        "\n",
        "print(f\"\\nAfter this round best effort: (Epoch  {epoch} > {epoch + epoch_round -1 })\")\n",
        "\n",
        "training_accuracy = check_accuracy(convnet, training_dataloader)\n",
        "print(f'Training   accuracy: {training_accuracy * 100 :.2f}%')\n",
        "\n",
        "validation_accuracy = check_accuracy(convnet, validation_dataloader)\n",
        "print(f'Validation accuracy: {validation_accuracy * 100 :.2f}%')\n",
        "\n",
        "test_accuracy = check_accuracy(convnet, test_dataloader)\n",
        "print(f'Test accuracy: {test_accuracy * 100 :.2f}%')\n",
        "epoch += epoch_round\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "fD3u4IhZzVj7",
        "outputId": "d8d09074-f182-4720-d284-165bb0850b05"
      },
      "outputs": [],
      "source": [
        "def acc_plot():\n",
        "  font = {'family': 'DejaVu Sans', 'weight': 'normal', 'size': 12}\n",
        "  plt.figure(10)\n",
        "  plt.rc('font', **font)\n",
        "  plt.rcParams.update({'lines.linewidth': 2})\n",
        "  plt.plot(training_accuracy_list, label=\"Training Accr.\")\n",
        "  plt.plot(validation_accuracy_list, label=\"Validation Accr.\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.legend()\n",
        "  plt.xlim(xmin=0)\n",
        "  return plt\n",
        "\n",
        "def loss_plot():\n",
        "  font = {'family': 'DejaVu Sans', 'weight': 'normal', 'size': 12}\n",
        "  plt.figure(11)\n",
        "  plt.rc('font', **font)\n",
        "  plt.rcParams.update({'lines.linewidth': 2})\n",
        "  plt.plot(range(1, epoch), loss_list, label=\"Loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend()\n",
        "  return plt\n",
        "\n",
        "\n",
        "display(loss_plot())\n",
        "display(acc_plot())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7YUjfF_zVj7"
      },
      "source": [
        "## Results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Result Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#load the best model\n",
        "convnet.load_state_dict(torch.load(model_save_file))\n",
        "convnet.eval()\n",
        "print(\"the best model is loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OH63cH81tg8a",
        "outputId": "594e44a8-3dae-438c-bc70-57fe0f04a5e0"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "\n",
        "os.makedirs(report_folder, exist_ok=True)\n",
        "\n",
        "results[\"Training\"] = check_accuracy(convnet, training_dataloader, show_report=True, show_matrix=True, save_matrix=f\"{report_folder}/Training.png\")\n",
        "results[\"Validation\"] = check_accuracy(convnet, validation_dataloader, show_report=True, show_matrix=True, save_matrix=f\"{report_folder}/Validation.png\")\n",
        "results[\"Test\"] = check_accuracy(convnet, test_dataloader, show_report=True, show_matrix=True, save_matrix=f\"{report_folder}/Test.png\")\n",
        "loss_plot().savefig(f\"{report_folder}/loss.png\", dpi=72, bbox_inches='tight')\n",
        "acc_plot().savefig(f\"{report_folder}/acc.png\", dpi=72, bbox_inches='tight')\n",
        "draw_canvas(convnet, test_dataloader, save_fig=f\"{report_folder}/sample.png\")\n",
        "draw_canvas(convnet, test_dataloader, only_errors=True, save_fig=f\"{report_folder}/sample_err.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "  <style>\n",
        "    html{\n",
        "      font-family: \"Times New Roman\", Times, serif;\n",
        "      font-size: 12pt;\n",
        "    }\n",
        "    table {\n",
        "      border-spacing: 0px;\n",
        "    }\n",
        "\n",
        "    div.centered \n",
        "    {\n",
        "        text-align: center;\n",
        "    }\n",
        "\n",
        "    div.centered table \n",
        "    {\n",
        "        margin: 0 auto; \n",
        "        text-align: left;\n",
        "    }\n",
        "\n",
        "    th {\n",
        "      text-align: center;\n",
        "      border-bottom: 2px solid black;\n",
        "      padding: 2px 5px 2px 5px;\n",
        "    }\n",
        "    td {\n",
        "      text-align: right;\n",
        "      padding: 5px;\n",
        "    }\n",
        "    img{\n",
        "      text-align:center;\n",
        "    }\n",
        "    caption{\n",
        "      padding-bottom:10px;\n",
        "    }\n",
        "  </style>\n",
        "  <meta charset=\"utf-8\">\n",
        "  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
        "</head>\n",
        "<body>\n",
        "  <p><b>{{run}}</b></p>\n",
        "  <p><b>{{title}}</b></p>\n",
        "  <p>Total Duration: {{\"%.2f\"|format(elapsed)}} sec.</p>\n",
        "  <p>Learning Rate: {{\"%.6f\"|format(learning_rate)}}</p>\n",
        "  <p>Dropout: {{\"%.2f\"|format(dropout)}}</p>\n",
        "  <p>Batch Size: {{ batch_size }}</p>\n",
        "  <p>Epoch: {{ epoch }}</p>\n",
        "  <p>Best Performing Epoch: {{ best_epoch }}</p>\n",
        "  <div class=\"centered\">\n",
        "    <table cellspacing=\"0\" cellpadding=\"0\" lang=\"en\">\n",
        "      <caption>Summary<br/></caption>\n",
        "      <tr>\n",
        "        <th>Method</th>\n",
        "        <th>Accuracy</th>\n",
        "      </tr>\n",
        "      {% for key,value in summary.items() %}\n",
        "      <tr>\n",
        "        <td style=\"text-align: left;\"><b>{{key}}</b></td>\n",
        "        <td>{{\"%.4f\"|format(value.accuracy)}}</td>\n",
        "      </tr>\n",
        "      {% endfor %}\n",
        "    </table>\n",
        "  </div>\n",
        "  <br clear=all style='page-break-before:always'>\n",
        "  <div class=\"centered\">\n",
        "    <figure>\n",
        "      <img src=\"loss.png\" align=\"center\" /><br/>\n",
        "      <figcaption>Loss Plot</figcaption>\n",
        "    </figure>\n",
        "  </div>\n",
        "  <p><br/><br/></p>\n",
        "  <div class=\"centered\">\n",
        "    <figure>\n",
        "      <img src=\"acc.png\" align=\"center\" /><br/>\n",
        "      <figcaption>Accuracy Plot</figcaption>\n",
        "    </figure>\n",
        "  </div>\n",
        "  <br clear=all style='page-break-before:always'>      \n",
        "{% for result in data %}\n",
        "  <p><b>{{result.title}} Result</b></p>\n",
        "  <div class=\"centered\">\n",
        "    <table cellspacing=\"0\" cellpadding=\"0\" lang=\"en\">\n",
        "      <caption>{{result.title}} Classification Report<br/></caption>\n",
        "      <tr>\n",
        "        <th></th>\n",
        "        <th>Precision</th>\n",
        "        <th>Recall</th>\n",
        "        <th>F1 Score</th>\n",
        "        <th>Support</th>\n",
        "      </tr>\n",
        "      {% for key,value in result.report.items() %}\n",
        "      {% if key==\"micro avg\" or key==\"accuracy\" %}\n",
        "      <tr>\n",
        "        <td>&nbsp;</td>\n",
        "        <td>&nbsp;</td>\n",
        "        <td>&nbsp;</td>\n",
        "        <td>&nbsp;</td>\n",
        "        <td>&nbsp;</td>\n",
        "      </tr>\n",
        "      {% endif %}\n",
        "      {% if key != \"accuracy\" %}\n",
        "      <tr>\n",
        "        <td style=\"text-align: left;\"><b>{{key}}</b></td>\n",
        "        <td>{{\"%.4f\"|format(value.precision) }}</td>\n",
        "        <td>{{\"%.4f\"|format(value.recall)}}</td>\n",
        "        <td>{{\"%.4f\"|format(value.get('f1-score'))}}</td>\n",
        "        <td>{{value.support}}</td>\n",
        "      </tr>\n",
        "      {% else %}\n",
        "      <tr>\n",
        "        <td style=\"text-align: left;\"><b>{{key}}</b></td>\n",
        "        <td></td>\n",
        "        <td></td>\n",
        "        <td>{{\"%.4f\"|format(value)}}</td>\n",
        "        <td></td>\n",
        "      </tr>\n",
        "      {% endif %}\n",
        "      {% endfor %}\n",
        "    </table>\n",
        "    </div>\n",
        "    <br clear=all style='page-break-before:always'>\n",
        "    <div class=\"centered\">\n",
        "      <figure>\n",
        "        <img src=\"{{result.method}}.png\" align=\"center\" />\n",
        "        <figcaption>{{result.title}} Confusion Matrix</figcaption>\n",
        "      </figure>\n",
        "    </div>\n",
        "    <br clear=all style='page-break-before:always'>\n",
        "{% endfor %}\n",
        "    <div class=\"centered\">\n",
        "      <figure>\n",
        "        <img src=\"sample.png\" align=\"center\" style=\"width:95%\" /><br/>\n",
        "        <figcaption>Sample Images from Test Dataset</figcaption>\n",
        "      </figure>\n",
        "    </div>\n",
        "    <br clear=all style='page-break-before:always'>\n",
        "    <div class=\"centered\">\n",
        "      <figure>\n",
        "        <img src=\"sample_err.png\" align=\"center\" style=\"width:95%\" /><br/>\n",
        "        <figcaption>Sample Images that cannot be accurately predicted in the Test Dataset</figcaption>\n",
        "      </figure>\n",
        "    </div>\n",
        "\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "environment = Environment()\n",
        "template = environment.from_string(template)\n",
        "font = {'family': 'DejaVu Sans', 'weight': 'normal', 'size': 6}\n",
        "plt.rc('font', **font)\n",
        "\n",
        "data = []\n",
        "summary = dict()\n",
        "\n",
        "for dataset_name, result in results.items():\n",
        "\n",
        "  runs = {\n",
        "      3: \"Unrefined Dataset Improvement Run\",\n",
        "      4: \"Manually Validated Dataset Improvement Run\",\n",
        "      5: \"Automatic Validation Model Training Run\",\n",
        "      6: \"Refined Dataset Improvement Run\"\n",
        "  }\n",
        "\n",
        "  method_pretty = f\"{dataset_name} Dataset\".replace('_', ' ').title()\n",
        "\n",
        "  data.append(dict(method=dataset_name, title=method_pretty, report=result))\n",
        "\n",
        "  accuracy = result['micro avg']['f1-score'] if ('micro avg' in result) else result['accuracy']\n",
        "  summary[method_pretty] = dict(accuracy=accuracy)\n",
        "\n",
        "\n",
        "title = f\"CNN {model_name.title()}\"\n",
        "if dataset_id != 5:\n",
        "  title += f\" {'Single Color' if no_multicolor else 'Multi-Color'} with {str(color_space).upper()}\"\n",
        "\n",
        "render = template.render(run=runs[dataset_id], title=title, data=data, summary=summary, elapsed=elapsed, color_space=color_space,\n",
        "                         learning_rate=learning_rate, dropout=dropout, batch_size=batch_size, epoch=epoch - 1, best_epoch=best_epoch)\n",
        "\n",
        "\n",
        "with open(f\"{report_folder}/report.html\", mode='w', encoding='utf-8') as file:\n",
        "  file.write(render)\n",
        "\n",
        "display(HTML(render))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "interpreter": {
      "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
    },
    "kernelspec": {
      "display_name": "Python 3.10.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
